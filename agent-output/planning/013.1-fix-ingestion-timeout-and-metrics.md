# Plan 013.1: Fix Ingestion Timeout and Add Performance Metrics

**Plan ID**: 013.1  
**Target Release**: v0.2.2.1  
**Epic Alignment**: Epic 0.2.2.3 (Discoverability and UX) - supplemental to Plan 013  
**Status**: Pending Implementation  
**Related Analysis**: `agent-output/analysis/013.1-ingestion-timeout-and-metrics-analysis.md`

---

## Value Statement and Business Objective

As a Cognee extension user, I want ingestion timeouts and error messages to accurately reflect the true state and performance of the ingestion pipeline, so that I can trust the extension's feedback, avoid chasing false failures when data is actually ingested correctly, and continuously improve ingestion latency through data-driven insights.

**Measurable Success Criteria**:
- Reduce false-positive timeout errors from "sometimes occurs" to zero under normal usage (ingestion <120s)
- User sees clear distinction between "timeout waiting" vs "ingestion failed" errors
- Extension logs include Python-side ingestion duration and step-level metrics for all ingestion attempts
- Correlation between Python-side duration and Node-side duration enables diagnosis of bridge vs backend latency

---

## Objective

Fix misleading ingestion timeout errors that report "ingestion failed" when data is actually ingested successfully, and add comprehensive performance metrics to diagnose where ingestion time is spent.

**Current Problem**:
- User runs "Capture Cognee Memory" command
- Extension sometimes logs: `Python script timeout after 30 seconds` + `Ingestion exception`
- User believes ingestion failed
- However, `@cognee-memory` search shows data is present (ingestion actually succeeded)
- This creates confusion and distrust in the extension's status reporting

**Root Cause** (uncertain, requires measurement):
- Either: Cognee ingestion (`add` + `cognify`) genuinely takes >30 seconds, OR
- Ingestion completes <30s but Node's spawn/IO doesn't detect completion before timeout
- We lack metrics to distinguish between these scenarios

**Solution**:
1. Increase timeout from 30s to 120s (immediate relief)
2. Improve error messages to distinguish timeout from true failure
3. Add comprehensive metrics to measure actual ingestion duration and identify bottlenecks

---

## Assumptions

### Validated Assumptions
1. **False timeout errors occur**: Confirmed by user report (timeout logged but data present)
2. **Python process not killed**: `runPythonScript` timeout rejects promise but doesn't kill process
3. **Data integrity unaffected**: User confirms `@cognee-memory` retrieval works after timeout

### Unvalidated Assumptions (to be tested by metrics)
1. **Ingestion duration >30s**: We assume Cognee operations sometimes exceed 30s, but have no data
2. **Bridge signaling overhead minimal**: We assume Node spawn/IO overhead is negligible, but have no data
3. **120s timeout sufficient**: Based on typical LLM latency + processing, 120s should cover 95%+ cases

### Open Questions
1. Does ingestion duration vary significantly by conversation length, workspace size, or first-time setup?
2. Which step consumes most time: `add` vs `cognify` vs initialization?
3. Should timeout be user-configurable in extension settings?

---

## Plan

### Milestone 1: Increase Ingestion Timeout

**Objective**: Reduce false-positive timeout errors by increasing timeout from 30s to 120s.

**Tasks**:
1. Update `extension/src/cogneeClient.ts`:
   - Change `ingestConversation` timeout from `30000` to `120000` ms
   - Update related comments explaining timeout rationale
2. Update `extension/README.md`:
   - Update troubleshooting table timeout references (currently mentions 10s/30s)
   - Document new 120s timeout with rationale

**Acceptance**: Ingestion timeout increased to 120s, documentation updated.

---

### Milestone 2: Improve User-Facing Error Messages

**Objective**: Distinguish between timeout (ingestion may still succeed) and true failure (ingestion confirmed failed).

**Tasks**:
1. Update `extension/src/cogneeClient.ts` `ingestConversation` catch block:
   - Detect timeout error via pattern match: `/Python script timeout after/`
   - For timeout errors:
     - Log with `error_type: 'timeout'` (distinct from `'failure'`)
     - Return or throw with clearer message: "Cognee is still working on ingestion in the background. The extension timed out waiting for a response after 120 seconds. Your data may still be ingested; you can check by querying @cognee-memory in a moment."
   - For non-timeout errors:
     - Log with `error_type: 'failure'`
     - Keep existing error message (already surfaces structured errors from Python)
2. Update any UI surfaces (status bar, notifications) that consume ingestion status:
   - Show timeout-specific message vs failure message based on error categorization

**Acceptance**: Timeout errors display user-friendly message explaining background ingestion may still succeed; true failures display existing error details.

---

### Milestone 3: Add Python-Side Ingestion Duration Metrics

**Objective**: Measure actual ingestion duration on Python side, independent of Node timeout.

**Tasks**:
1. Update `extension/bridge/ingest.py`:
   - Import `from time import perf_counter`
   - Add `overall_start = perf_counter()` before Cognee operations
   - After `cognee.cognify(...)` completes, compute `ingestion_duration = perf_counter() - overall_start`
   - Add to success JSON response:
     ```python
     return {
         'success': True,
         'ingested_chars': ingested_chars,
         'timestamp': timestamp,
         'ingestion_duration_sec': ingestion_duration
     }
     ```
   - Log to `stderr`: `print(f"Ingestion duration: {ingestion_duration:.3f} seconds", file=sys.stderr)`
2. Update `extension/src/cogneeClient.ts` `ingestConversation` success path:
   - Parse `ingestion_duration_sec` from result JSON
   - Log both durations:
     ```ts
     this.log('INFO', 'Conversation ingested', {
       chars: result.ingested_chars,
       timestamp: result.timestamp,
       duration_ms: duration,
       ingestion_duration_sec: result.ingestion_duration_sec
     });
     ```

**Acceptance**: Extension logs include both Node-measured duration (`duration_ms`) and Python-measured duration (`ingestion_duration_sec`) for successful ingestions.

---

### Milestone 4: Add Step-Level Ingestion Metrics

**Objective**: Identify which steps consume most time (initialization, `add`, `cognify`, etc.).

**Tasks**:
1. Update `extension/bridge/ingest.py`:
   - Create `metrics = {}` dict at start
   - Wrap each major step with timing:
     ```python
     step_start = perf_counter()
     # ... step code ...
     metrics['step_name_sec'] = perf_counter() - step_start
     ```
   - Steps to instrument:
     - `load_env_sec`: Load `.env` and check `LLM_API_KEY`
     - `init_cognee_sec`: Import cognee, configure directories
     - `config_llm_sec`: Configure LLM provider/API key
     - `dataset_ontology_sec`: Generate dataset name, resolve ontology
     - `add_sec`: `await cognee.add(...)`
     - `cognify_sec`: `await cognee.cognify(...)`
     - `total_ingest_sec`: Overall ingestion time (should match `ingestion_duration_sec`)
   - Log to `stderr`: `print(f"Ingestion metrics: {json.dumps(metrics)}", file=sys.stderr)`
   - Add to success JSON response:
     ```python
     return {
         'success': True,
         'ingested_chars': ingested_chars,
         'timestamp': timestamp,
         'ingestion_duration_sec': metrics['total_ingest_sec'],
         'ingestion_metrics': metrics
     }
     ```
2. Update `extension/src/cogneeClient.ts` `ingestConversation` success path:
   - Parse `ingestion_metrics` from result JSON
   - Log metrics (optionally truncated if verbose):
     ```ts
     this.log('DEBUG', 'Ingestion metrics', {
       metrics: result.ingestion_metrics
     });
     ```

**Acceptance**: Extension logs include step-level timing metrics (`add_sec`, `cognify_sec`, etc.) for all successful ingestions.

---

### Milestone 5: Log Process Exit vs Timeout in runPythonScript

**Objective**: Distinguish between timeout firing before process exit vs process exit occurring but Node not detecting it.

**Tasks**:
1. Update `extension/src/cogneeClient.ts` `runPythonScript` method:
   - Add variables:
     ```ts
     let timedOut = false;
     const requestStart = Date.now();
     let timeoutFiredAt: number | null = null;
     ```
   - Update timeout handler:
     ```ts
     const timeout = setTimeout(() => {
       timedOut = true;
       timeoutFiredAt = Date.now();
       this.log('ERROR', 'Python script timeout', {
         script: scriptName,
         timeout: timeoutMs,
         elapsed_ms: timeoutFiredAt - requestStart
       });
       reject(new Error(`Python script timeout after ${timeoutMs/1000} seconds`));
     }, timeoutMs);
     ```
   - Update `python.on('close')` handler:
     ```ts
     python.on('close', (code) => {
       const closeTime = Date.now();
       this.log('DEBUG', 'Python script completed', {
         script: scriptName,
         exit_code: code,
         close_duration_ms: closeTime - requestStart,
         timed_out: timedOut,
         timeout_fired_ms: timeoutFiredAt ? timeoutFiredAt - requestStart : null
       });
       
       if (timedOut) {
         // Process completed after promise was already rejected
         return;
       }
       
       clearTimeout(timeout);
       // ... existing success/error handling ...
     });
     ```

**Acceptance**: Extension logs show `timed_out`, `timeout_fired_ms`, and `close_duration_ms` for all Python script invocations, enabling diagnosis of timing issues.

---

### Milestone 6: Update Version and Release Artifacts

**Objective**: Update project version to v0.2.2.1 and document changes for roadmap alignment.

**Tasks**:
1. Update `extension/package.json`: `"version": "0.2.2.1"`
2. Update `extension/CHANGELOG.md`: Add entry under `[0.2.2.1]` section:
   ```markdown
   ### Fixed
   - Ingestion timeout increased from 30s to 120s to reduce false-positive failures
   - Error messages now distinguish timeout (may still succeed) from true ingestion failure
   - Added comprehensive ingestion performance metrics (Python-side duration, step-level timing)
   - Added process exit vs timeout logging for diagnosing bridge-level latency
   ```
3. Commit version changes with message: "Release v0.2.2.1 - Plan 013.1: Fix ingestion timeout and add metrics"

**Acceptance**: Version artifacts updated, CHANGELOG reflects changes, version matches roadmap target.

---

## Testing Strategy

### Unit Testing
- **Target**: Python bridge scripts (`ingest.py`)
- **Coverage**: Ensure metrics collection doesn't break existing ingestion logic
- **Tests**:
  - Verify `ingestion_duration_sec` and `ingestion_metrics` are included in success JSON
  - Verify metrics keys match expected names (`add_sec`, `cognify_sec`, etc.)
  - Verify metrics are logged to `stderr`

### Integration Testing
- **Target**: End-to-end ingestion via `cogneeClient.ts`
- **Coverage**: Verify timeout increase and error categorization work correctly
- **Tests**:
  - Ingest conversation with normal duration (<120s): verify success, logs include metrics
  - Mock slow ingestion (>120s): verify timeout error, message distinguishes from failure
  - Mock Python error (e.g., missing API key): verify failure error, distinct from timeout

### Manual Testing (UAT Scenarios)
1. **Baseline ingestion**: Capture short conversation, verify success logs include `ingestion_duration_sec` and `ingestion_metrics`
2. **Slow ingestion simulation**: Temporarily reduce timeout to 5s, capture conversation, verify timeout message is clear and mentions background processing
3. **Failed ingestion**: Remove `LLM_API_KEY` from `.env`, capture conversation, verify failure message is distinct from timeout
4. **Metrics analysis**: Capture several conversations, review logs to identify which step (`add` vs `cognify`) consumes most time
5. **Process exit timing**: Review logs for `timed_out`, `timeout_fired_ms`, `close_duration_ms` to confirm Python process behavior

---

## Validation

### Success Criteria
- [ ] Ingestion timeout increased to 120s (Milestone 1)
- [ ] Timeout errors display user-friendly message explaining background processing (Milestone 2)
- [ ] True failure errors display structured error details (Milestone 2)
- [ ] Extension logs include Python-side `ingestion_duration_sec` for all successful ingestions (Milestone 3)
- [ ] Extension logs include step-level metrics (`add_sec`, `cognify_sec`, etc.) for all successful ingestions (Milestone 4)
- [ ] Extension logs include process timing details (`timed_out`, `timeout_fired_ms`, `close_duration_ms`) for all Python invocations (Milestone 5)
- [ ] Version updated to v0.2.2, CHANGELOG reflects changes (Milestone 6)

### Metrics to Monitor Post-Deployment
- Average `ingestion_duration_sec`: Expect 5-30s for typical conversations
- `add_sec` vs `cognify_sec`: Which step is slower on average?
- Frequency of timeouts (should be rare with 120s limit)
- Correlation between `duration_ms` and `ingestion_duration_sec * 1000`: Should be roughly equal if bridge overhead is minimal

---

## Risks

### Risk 1: 120s timeout still insufficient for some users
**Likelihood**: Low  
**Impact**: Medium (users still see timeouts, but less frequently)  
**Mitigation**: Monitor post-deployment metrics; if timeouts persist, consider making timeout user-configurable in extension settings

### Risk 2: Metrics collection overhead slows ingestion
**Likelihood**: Very Low  
**Impact**: Low (would slightly increase ingestion time)  
**Mitigation**: Use `perf_counter()` which has negligible overhead; step-level timing only logs to stderr and JSON, doesn't perform heavy computation

### Risk 3: Error message changes confuse existing users
**Likelihood**: Very Low  
**Impact**: Low (existing users rarely see timeouts)  
**Mitigation**: Timeout message is additive (new clarification); failure messages unchanged; CHANGELOG documents change

### Risk 4: Metrics don't reveal root cause (still unclear if slow backend vs slow bridge)
**Likelihood**: Low  
**Impact**: Medium (requires additional investigation)  
**Mitigation**: Metrics provide baseline data; if root cause still unclear, can add follow-up instrumentation (e.g., subprocess spawn timing, stdout flush timing)

---

## Rollback Plan

If ingestion breaks or metrics cause issues:

1. **Revert timeout change**: Change `120000` back to `30000` in `cogneeClient.ts`
2. **Revert metrics collection**: Remove timing code from `ingest.py`, remove `ingestion_duration_sec` and `ingestion_metrics` from JSON response
3. **Revert error message changes**: Remove timeout detection and user-facing message changes from `ingestConversation`
4. **Revert process timing logs**: Remove `timedOut`, `timeout_fired_ms`, `close_duration_ms` from `runPythonScript`
5. **Tag safe commit**: Before deployment, tag current working commit as `v0.2.1-stable` for easy rollback

---

## Dependencies

- None (this is an incremental improvement to existing ingestion functionality)

---

## Related Artifacts

- **Analysis**: `agent-output/analysis/013.1-ingestion-timeout-and-metrics-analysis.md`
- **Roadmap**: `agent-output/roadmap/product-roadmap.md` - Epic 0.2.2.3
- **Architecture**: `agent-output/architecture/system-architecture.md` - Section 4.3 (Python Bridge Architecture)
- **Prior Plan**: `agent-output/planning/013-fix-memory-display-truncation.md` (Plan 013)
