# Plan 014.1: Agent Command Invocation Feasibility Analysis

**Plan ID**: 014.1
**Target Release**: v0.3.0 (prerequisite for v0.3.1)
**Created**: 2025-11-18
**Updated**: 2025-11-19 (COMPLETED - languageModelTools validated as primary Copilot integration path)
**Status**: ✅ COMPLETE
**Epic Alignment**: Epic 0.3.0.3 - Agent-Driven Memory Integration (prerequisite)
**Blocks**: Plan 015 (agent ingestion), Plan 016 (agent retrieval)
**Related Architecture**: `architecture/system-architecture.md` §3.1, §4.5, §9 (ADR: Copilot Tool Surface vs Direct Commands)

---

## Value Statement and Business Objective

As an architect planning agent-driven memory integration,
I want to validate that VS Code Copilot agents can invoke extension commands (or alternatively, that MCP server integration is viable),
So that Plans 015/016 can proceed with confidence in the chosen integration path and avoid implementing unusable APIs.

**Success Criteria**: ✅ ACHIEVED

- ✅ **DECISION: languageModelTools (Primary Path)** - VS Code's `languageModelTools` API confirmed as the officially supported mechanism for Copilot agent integration. Extension contributes tools (e.g., `cognee.retrieveMemory`, `cognee.storeMemory`) that proxy into internal commands.
- ✅ **Fallback Strategies Preserved** - Direct command invocation (`executeCommand`) remains supported for non-Copilot extensions; MCP server documented as contingency for other agent platforms.
- ✅ **Architecture Updated** - ADR "Copilot Tool Surface vs Direct Commands" (2025-11-19) documented in `system-architecture.md` §9.
- ✅ **Implementation Guidance** - Plans 015/016 can proceed with tool entry command + command proxy pattern; workspace-global access model with opt-in settings; rate limiting via `CogneeContextProvider`.
- ✅ **Validation Approach** - Tool registration/unregistration tied to workspace settings; audit logging for transparency; QA must verify tool metadata accuracy and hot-unregister on disable.

---

## Objective

Validate the technical feasibility of two integration paths for agent-driven memory:

1. **VS Code Command Invocation** (preferred for simplicity):
   - Create minimal test extension registering a command.
   - **CRITICAL**: Validate that **GitHub Copilot agents** (not just regular extensions) can invoke the command via `vscode.commands.executeCommand`.
   - Establish baseline: Test extension-to-extension invocation to confirm command infrastructure works.
   - Primary test: Create Copilot chat participant that invokes command, or research official documentation if empirical testing unavailable.
   - Document: Does VS Code expose caller identity? Can we enforce authorization? Are there API version constraints?

2. **MCP Server Fallback** (if command invocation fails):
   - Create minimal MCP server exposing a test tool.
   - Attempt to connect from VS Code extension context.
   - Document: How do agents discover the server? What authentication is required? Can we enforce workspace-global access model?

**Dependencies**:

- None (this is a prerequisite analysis plan with no code dependencies).

**Out of Scope**:

- Full implementation of `ingestForAgent` or `retrieveForAgent` commands (deferred to Plans 015/016).
- Production-ready MCP server (only proof-of-concept to validate feasibility).
- Deep changes to Cognee bridge or extension architecture (this plan only tests integration surface).

---

## Assumptions

1. **VS Code API Access**: Test can use stable VS Code extension APIs (v1.85+); no insider builds required.
2. **MCP Protocol Stability**: If testing MCP path, use published MCP specification (not in-flight changes).
3. **Copilot Agent Model**: Assume agents can either (a) call `vscode.commands.executeCommand` programmatically, or (b) connect to local MCP servers if exposed by extensions.
4. **Time-Boxed Research**: Analysis limited to 2-3 days; inconclusive results should document open questions and recommend escalation/deferral.

---

## Plan

### Milestone 0: Setup Test Environment

**Objective**: Prepare minimal test workspace with two extensions: one registering commands/MCP tools, one attempting to invoke them.

**Tasks**:

1. **Create Test Extension A: Command Provider** (`test-extensions/command-provider/`)
   - Minimal VS Code extension registering command `testProvider.echo`.
   - Command signature: `(payload: string) => Promise<string>` (returns `{ echo: payload, timestamp: ... }`).
   - Register command in `activate()` via `vscode.commands.registerCommand`.
   - Log all invocations to Output channel with caller context (if available).
   - **Acceptance**: Extension packages successfully; command registered and discoverable.

2. **Create Test Extension B: Command Consumer** (`test-extensions/command-consumer/`)
   - Minimal VS Code extension attempting to call `testProvider.echo`.
   - Use `vscode.commands.executeCommand<string>('testProvider.echo', JSON.stringify({ test: 'hello' }))`.
   - Log response and any errors to Output channel.
   - **Acceptance**: Extension packages successfully; can attempt command invocation.

3. **Document Test Workspace Setup**
   - Create `test-extensions/README.md` with setup instructions:
     - Build both extensions.
     - Install both in VS Code (or run in Extension Development Host).
     - Invoke consumer extension's test command.
     - Inspect Output logs from both extensions.
   - **Acceptance**: QA can reproduce test without additional guidance.

**Owner**: Analyst (or implementer if analyst unavailable)
**Dependencies**: None
**Validation**: Test extensions build; setup documented.

---

### Milestone 1: Test VS Code Command Invocation Path

**Objective**: Validate whether extensions can call each other's commands and document constraints.

**Tasks**:

1. **Execute Cross-Extension Command Invocation (Baseline)**
   - Install both test extensions in VS Code.
   - Trigger command consumer's test command (e.g., via command palette or activation event).
   - Observe:
     - Does `executeCommand` succeed?
     - Does provider extension receive the call?
     - Does consumer receive the response?
   - **Purpose**: Establish baseline that command infrastructure works, but **this does not validate Copilot agent behavior**.
   - **Acceptance**: Test executed; results logged in both Output channels; documented as baseline only.

2. **Investigate Caller Identity**
   - In provider extension, inspect command handler arguments and VS Code API context.
   - Research: Does `vscode.commands.registerCommand` handler receive caller extension ID, authentication token, or capability proof?
   - Document findings in `test-extensions/FINDINGS.md`:
     - Can we identify calling extension? (Yes/No + API details)
     - Can we enforce per-extension allow-lists? (Yes/No + implementation guidance)
     - Can we detect if caller is a Copilot agent vs third-party extension? (Yes/No)
   - **Acceptance**: Caller identity investigation documented with code examples.

3. **Test Authorization Patterns**
   - Implement workspace setting `testProvider.allowedExtensions: string[]` in provider extension.
   - Attempt to enforce allow-list in command handler (if caller identity available).
   - Document: Does enforcement work? What are limitations?
   - **Alternative**: If caller identity unavailable, document workspace-global access model as only option.
   - **Acceptance**: Authorization approach documented; limitations clear.

4. **Validate Copilot Agent Compatibility (CRITICAL - PRIMARY OBJECTIVE)**
   - **REQUIRED TEST**: Create a minimal GitHub Copilot chat participant that attempts to invoke `testProvider.echo` via `vscode.commands.executeCommand`.
   - Test procedure:
     - Implement chat participant in test extension (or standalone).
     - Register participant with VS Code Chat API (`vscode.chat.createChatParticipant`).
     - Have participant invoke `testProvider.echo` in response to user query.
     - Document: Does invocation succeed? Does response flow back to agent?
   - Research: Check VS Code Chat API documentation and GitHub Copilot extension samples for command invocation patterns.
   - **If empirical testing is not feasible** (e.g., Copilot API unavailable, requires special credentials):
     - Document research findings from official VS Code/GitHub documentation.
     - Consult VS Code extension samples for chat participant command invocation examples.
     - Findings must:
       - Explicitly label the command invocation recommendation as **PROVISIONAL**.
       - Require Plans 015/016 to validate Copilot invocation in Milestone 0 (before implementing full feature).
       - Design Plans 015/016 with thin abstraction layer so integration surface (commands vs MCP) can be swapped if Copilot assumption proves incorrect.
   - **Acceptance**: Copilot compatibility documented (CONFIRMED if tested empirically, PROVISIONAL if based on research only); provisional status clearly flagged; Plans 015/016 validation requirements explicit.

5. **Document Command Invocation Findings**
   - Update `test-extensions/FINDINGS.md` with:
     - Path 1 Feasibility: CONFIRMED (Copilot tested) / PROVISIONAL (research only) / BLOCKED
     - Extension-to-extension baseline: Success / Failure
     - **Copilot agent invocation**: EMPIRICALLY TESTED (success/failure) / RESEARCH ONLY (assumed from docs)
     - Caller identity: Available / Not available
     - Authorization model: Per-extension / Workspace-global / Not enforceable
     - Recommended approach if Path 1 viable: workspace-global access with opt-in settings.
   - **Acceptance**: Findings documented; distinction between extension baseline and Copilot agent behavior clear; decision criteria explicit.

**Owner**: Analyst
**Dependencies**: Milestone 0 (test extensions ready)
**Validation**: Command invocation tested; findings documented in `FINDINGS.md`.

---

### Milestone 2: Test MCP Server Fallback Path (Conditional)

**Objective**: If Path 1 (command invocation) is blocked or insufficient, validate MCP server integration as fallback.

**Trigger**: Execute this milestone only if Milestone 1 findings conclude Path 1 is BLOCKED or lacks critical capabilities (e.g., no authorization possible, Copilot agents cannot invoke commands).

**Tasks**:

1. **Create Minimal MCP Server** (`test-extensions/mcp-server/`)
   - Implement minimal MCP server exposing tool `test.echo`.
   - Tool signature: accepts `{ message: string }`, returns `{ echo: message, timestamp: ... }`.
   - Run server on localhost with configurable port (default: 3000).
   - **MCP Spec Documentation (REQUIRED)**: Document in `FINDINGS.md`:
     - Exact MCP protocol specification URL and version (e.g., `https://spec.modelcontextprotocol.io/2024-11-05`).
     - Library/implementation used (repo URL, version tag/commit hash).
     - Mark as "POC-only" to avoid locking future architecture into a non-evaluated stack.
   - Document server lifecycle (how to start, stop, verify running).
   - **Acceptance**: MCP server runs; exposes tool via MCP protocol; spec version and library documented in `FINDINGS.md`.

2. **Integrate MCP Server into Provider Extension**
   - Modify provider extension to spawn MCP server process on activation.
   - Expose server connection details (port, auth token if needed) via VS Code settings or output channel.
   - Ensure server terminates when extension deactivates.
   - **Acceptance**: Extension can start/stop MCP server; lifecycle managed correctly.

3. **Test MCP Tool Invocation from Consumer Extension**
   - Modify consumer extension to connect to MCP server (use MCP client library if available).
   - Attempt to invoke `test.echo` tool.
   - Log response and any connection/auth errors.
   - **Acceptance**: Consumer can call MCP tool; results logged.

4. **Investigate MCP Discovery and Authentication**
   - Research: How do VS Code agents discover MCP servers exposed by extensions?
     - Do extensions advertise MCP endpoints via VS Code API?
     - Do agents need manual configuration (server URL, auth tokens)?
   - Document: What authentication model does MCP support?
     - Token-based? Capability tokens? No auth (localhost only)?
   - **Acceptance**: Discovery and auth mechanisms documented.

5. **Test Workspace-Global Access Model with MCP**
   - Implement opt-in setting `testProvider.mcpAccess.enabled` in provider extension.
   - Block MCP tool invocations if setting disabled.
   - Document: Can we identify calling agent via MCP protocol? (Client ID, signed payloads?)
   - **Acceptance**: Access control tested; limitations documented.

6. **Document MCP Fallback Findings**
   - Update `test-extensions/FINDINGS.md` with:
     - Path 2 Feasibility: CONFIRMED / PARTIAL / BLOCKED
     - Discovery mechanism: VS Code API / Manual configuration / Other
     - Authentication model: Token-based / No auth / Other
     - Authorization model: Per-agent / Workspace-global / Not enforceable
     - Copilot compatibility: Confirmed / Assumed / Unknown
     - Recommended approach if Path 2 viable: workspace-global access with MCP server lifecycle management.
   - **Acceptance**: MCP fallback findings documented; decision criteria clear.

**Owner**: Analyst
**Dependencies**: Milestone 1 (Path 1 findings indicate MCP testing needed)
**Validation**: MCP server tested; findings documented in `FINDINGS.md`.

---

### Milestone 3: Decision and Recommendation

**Objective**: Synthesize findings from Milestones 1 and 2 into actionable decision for Plans 015/016.

**Tasks**:

1. **Assess Feasibility of Both Paths**
   - Path 1 (Commands): Feasibility rating (CONFIRMED / PARTIAL / BLOCKED).
   - Path 2 (MCP): Feasibility rating (CONFIRMED / PARTIAL / BLOCKED / NOT TESTED).
   - **Time-Box Prioritization (2-3 days total)**:
     - Path 1 (commands) is **REQUIRED** and must be fully tested/documented within time-box.
     - Path 2 (MCP) may be limited to desk research + minimal spike if time remains; if time runs out, document MCP as "PARTIALLY INVESTIGATED" with explicit TODOs rather than omitting it.
   - Document trade-offs:
     - Path 1 pros: Simpler for third-party extensions, no server lifecycle management.
     - Path 1 cons: Limited authorization, workspace-global access only.
     - Path 2 pros: Richer protocol, potential for finer-grained auth.
     - Path 2 cons: Server lifecycle complexity, agent discovery unclear.
   - **Acceptance**: Trade-off analysis documented; time-box adherence confirmed.

2. **Make Recommendation**
   - **Explicit Decision Criteria**:
     - **Default to commands** unless:
       - (a) Copilot cannot invoke commands at all (empirically confirmed or documented API limitation), OR
       - (b) A hard security/privacy requirement emerges that commands cannot meet (e.g., per-agent authorization is mandated by architect).
     - If Copilot invocation is assumed but not tested, recommendation must be **PROVISIONAL** and require early validation in Plans 015/016.
   - **Recommendation Patterns**:
     - **If Path 1 CONFIRMED and Copilot tested**: Recommend implementing Plans 015/016 using VS Code commands with workspace-global access model. Mark as **FIRM**.
     - **If Path 1 CONFIRMED but Copilot untested**: Recommend commands but mark as **PROVISIONAL**; require Plans 015/016 Milestone 0 to validate Copilot behavior before shipping public APIs.
     - **If Path 1 PARTIAL and Path 2 CONFIRMED**: Recommend hybrid approach: start with commands (simpler), add MCP fallback in future release if needed.
     - **If Path 1 BLOCKED and Path 2 CONFIRMED**: Recommend implementing Plans 015/016 using MCP server tools. Document server lifecycle requirements.
     - **If both paths BLOCKED or PARTIAL**: Recommend escalation to roadmap agent; defer agent-driven memory integration until VS Code or Copilot APIs improve.
   - **Acceptance**: Clear recommendation documented with rationale; provisional vs firm status explicit.

3. **Update Plans 015/016 Dependencies**
   - Document in Plan 014.1 findings section: which path to implement.
   - Provide implementation guidance for Plans 015/016:
     - If commands: reference `test-extensions/command-provider/` as example.
     - If MCP: reference `test-extensions/mcp-server/` as example; document server lifecycle pattern.
   - **Acceptance**: Implementation guidance clear; Plans 015/016 can proceed without additional research.

4. **Document Open Questions and Risks**
   - List unresolved questions (e.g., "Copilot agent command invocation not tested; assumed based on documentation").
   - List known risks (e.g., "Workspace-global access model requires prominent user warnings").
   - Recommend mitigation strategies (e.g., "Add status bar indicator showing agent access enabled").
   - **Acceptance**: Open questions and risks documented; Plans 015/016 aware of constraints.

5. **Create Decision Summary**
   - Add section to `test-extensions/FINDINGS.md`:
     - **Decision**: Path 1 (commands) / Path 2 (MCP) / Defer
     - **Decision Status**: FIRM (empirically validated) / PROVISIONAL (assumed, requires validation in Plans 015/016)
     - **Rationale**: [technical reasoning; if provisional, explain untested assumptions]
     - **Implementation Guidance**: [link to example code, lifecycle patterns, settings structure]
     - **Validation Requirements** (if provisional): [specific tests Plans 015/016 must perform before shipping public APIs]
     - **Known Limitations**: [list constraints]
     - **Escalation Path**: [if decision is "Defer", document escalation to roadmap/architect]
   - **Acceptance**: Decision summary complete; provisional vs firm status explicit; actionable for Plans 015/016.

**Owner**: Analyst (or planner if synthesis required)
**Dependencies**: Milestones 1 and 2 (findings from both paths)
**Validation**: Decision documented; implementation guidance provided; Plans 015/016 unblocked.

---

### Milestone 4: Documentation and Handoff

**Objective**: Package findings and test artifacts for Plans 015/016 implementers and QA.

**Tasks**:

1. **Finalize `test-extensions/FINDINGS.md`**
   - Ensure all sections complete:
     - Path 1 findings (command invocation).
     - Path 2 findings (MCP fallback, if tested).
     - Trade-off analysis.
     - Decision and recommendation.
     - Implementation guidance.
     - Open questions and risks.
   - Add "Last Updated" timestamp and analyst sign-off.
   - **Acceptance**: Findings document complete and reviewed.

2. **Archive Test Extensions**
   - Commit test extensions to `test-extensions/` directory.
   - Ensure README includes:
     - Purpose of each extension.
     - Setup instructions.
     - How to reproduce tests.
     - Links to FINDINGS.md.
   - Tag test extensions with Plan 014.1 reference.
   - **Acceptance**: Test artifacts version-controlled; reproducible.

3. **Update Architecture Document**
   - Add decision entry to `architecture/system-architecture.md` §9:
     - **Follow existing ADR format** (Context, Choice, Alternatives Considered, Consequences, Related) to maintain consistency with existing decisions in §9.
     - Decision: "Agent Command Invocation Model"
     - Context: "Plan 014.1 validated VS Code command invocation (or MCP fallback) for agent-driven memory integration. [Include provisional status if Copilot untested.]"
     - Choice: [commands / MCP / deferred] + [FIRM / PROVISIONAL]
     - Alternatives Considered: [list both paths with feasibility ratings]
     - Consequences: [caller identity constraints, authorization model, lifecycle management, validation requirements for Plans 015/016 if provisional]
     - Related: Plan 014.1, Plans 015/016, Epic 0.3.0.3
   - **Acceptance**: Architecture document reflects decision using consistent ADR format; future plans reference it.

4. **Update Plans 015/016 with Findings Reference**
   - Add note to Plan 015 and Plan 016 dependencies sections:
     - "Implementation path determined by Plan 014.1: [commands / MCP]"
     - "See `test-extensions/FINDINGS.md` for technical constraints and example code."
   - Remove "Plan 019 feasibility analysis" references (replace with "Plan 014.1").
   - **Acceptance**: Plans 015/016 reference Plan 014.1; no duplicate feasibility work.

5. **Handoff to Critic for Review**
   - Submit Plan 014.1 and findings document to critic agent.
   - Request validation:
     - Are findings comprehensive?
     - Is decision justified?
     - Are implementation risks adequately documented?
   - **Acceptance**: Critic review complete; Plan 014.1 approved.

**Owner**: Analyst + Planner
**Dependencies**: Milestone 3 (decision made)
**Validation**: Documentation complete; test artifacts archived; Plans 015/016 updated; critic approval.

---

## Testing Strategy

This plan is primarily investigative, not production code, but still requires validation:

- **Reproducibility**: QA must be able to build and run test extensions following README instructions.
- **Findings Verification**: Critic validates that findings match test results (no unsubstantiated claims).
- **Decision Justification**: Architect confirms decision aligns with system architecture principles (privacy, simplicity, maintainability).

**Validation Scenarios**:

1. QA builds test extensions → installs in VS Code → reproduces command invocation test → confirms findings.
2. If MCP path tested, QA runs MCP server → connects from consumer extension → confirms tool invocation works.
3. Architect reviews decision → confirms alignment with three-layer architecture and privacy model.

---

## Validation

**Acceptance Criteria**:

- ✅ Test extensions created and documented (command provider, command consumer, optionally MCP server).
- ✅ Path 1 (VS Code commands) tested; findings documented (caller identity, authorization, Copilot compatibility).
- ✅ Path 2 (MCP fallback) tested if Path 1 insufficient; findings documented (discovery, auth, lifecycle).
- ✅ Decision made: which path to implement in Plans 015/016.
- ✅ Implementation guidance provided (example code, settings structure, lifecycle patterns).
- ✅ Open questions and risks documented; mitigation strategies proposed.
- ✅ Architecture document updated with decision entry.
- ✅ Plans 015/016 updated to reference Plan 014.1 findings.
- ✅ Critic and architect approval; no P0/P1 concerns.

**Sign-off**: Analyst + Architect + Critic review before Plans 015/016 proceed.

---

## Risks

1. **Inconclusive Copilot Findings**
   - Risk: Testing may not definitively answer whether Copilot agents can invoke commands (requires Copilot-specific testing).
   - Mitigation: 
     - Mark recommendation as **PROVISIONAL** if Copilot behavior untested.
     - Require Plans 015/016 to validate Copilot invocation in early milestones (before shipping public APIs).
     - Design Plans 015/016 with abstraction layer allowing integration surface swap (commands → MCP) without large refactor.
     - Document specific validation tests Plans 015/016 must perform.
   - **Impact**: If assumption proves incorrect after Plans 015/016 begin, pivot cost is minimized by abstraction design.

2. **Both Paths Blocked**
   - Risk: Neither commands nor MCP may be viable (e.g., VS Code APIs insufficient, MCP not supported by Copilot).
   - Mitigation: Escalate to roadmap agent; defer Epic 0.3.0.3 until platform capabilities improve.

3. **MCP Protocol Instability**
   - Risk: MCP specification may change, invalidating test findings.
   - Mitigation: Document MCP version tested; recommend re-validation before production MCP server ships.

4. **Time-Box Exceeded**
   - Risk: Analysis may uncover deeper complexity requiring >2-3 days research.
   - Mitigation: Time-box analysis; document partial findings with escalation recommendation if inconclusive.

---

## Open Questions

1. **Copilot Agent Command Invocation**: Can we definitively test Copilot agent command invocation without Copilot developer access? → **Resolution: Document assumption if testing unavailable; mark recommendation as PROVISIONAL; require Plans 015/016 Milestone 0/1 to validate before shipping APIs**.
2. **MCP Discovery in VS Code**: Is there a standard API for extensions to advertise MCP servers? → **Resolution: Research during Milestone 2 if Path 1 blocked; document findings in `FINDINGS.md`**.
3. **Authorization Granularity**: If caller identity unavailable, are capability tokens a viable alternative? → **Resolution: Document as future enhancement; start with workspace-global model**.
4. **Performance Impact**: What's the latency overhead of MCP server calls vs direct command invocation? → **Resolution: Measure during testing if time permits; document trade-offs or flag as future work**.
5. **MCP Spec Version**: Which MCP specification and library should be used for POC? → **Resolution: Document exact spec URL, version, and library (repo + tag) in `FINDINGS.md`; mark as POC-only to avoid premature lock-in**.

---

## References

- `agent-output/architecture/system-architecture.md` (§3.1, §4.5, §9)
- `agent-output/roadmap/product-roadmap.md` (Epic 0.3.0.3)
- `agent-output/planning/015-agent-ingestion-command.md` (blocked by this plan)
- `agent-output/planning/016-autonomous-agent-retrieval-and-integration.md` (blocked by this plan)
- VS Code Extension API: https://code.visualstudio.com/api/references/vscode-api
- MCP Protocol Specification: (link TBD during research)
