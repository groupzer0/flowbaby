# 018-v0.3.5-retrieval-fabrication-and-silent-failure-analysis

## Changelog
- 2025-11-21: Created analysis to investigate user reports of "retrieval fabrication" and "silent storage failure" in v0.3.5.

## Value Statement and Business Objective
As a developer using Cognee, I want the system to accurately report when it cannot find relevant information and to reliably notify me if background processing fails, so that I can trust the tool's output and take corrective action when storage operations fail.

## Objective
Investigate and identify the root causes of two reported issues in v0.3.5:
1. **Retrieval Fabrication**: The system appears to make up information or present irrelevant results as high-confidence context.
2. **Silent Storage Failure**: The system fails to store memories without notifying the user, despite the "staged" success message.

## Architectural Context
- **Retrieval**: The `retrieveMemory` tool calls `CogneeClient.retrieve`, which executes `retrieve.py`. This script uses `cognee.search` (hybrid graph/vector search) and returns structured results. The tool then formats these results for the LLM.
- **Ingestion**: The `storeMemory` tool (and manual capture) uses an async pattern (Plan 017). It calls `ingest.py --mode add-only` (synchronous, fast), then queues a background `ingest.py --mode cognify-only` task via `BackgroundOperationManager`.
- **Notification**: The `BackgroundOperationManager` is responsible for monitoring the background task and notifying the user of success or failure based on status stubs written by the python script.

## Root Cause Analysis

### 1. Retrieval Fabrication
**Symptom**: Users report the tool returns "fabricated" data.
**Investigation**:
- Reviewed `extension/bridge/retrieve.py`.
- Found that `cognee.search` is called with `query_type=SearchType.GRAPH_COMPLETION`.
- **Critical Finding**: `GRAPH_COMPLETION` is a **Generative** step (RAG), not just a retrieval step. It performs a search (likely hybrid) to find context, and then sends that context to an internal LLM to generate an answer.
- **Hallucination Source**: The hallucination comes specifically from the **LLM Generation** phase.
  - **Vector/Graph Retrieval**: Returns existing text chunks or nodes. If no relevant data exists, it returns nothing or irrelevant noise (garbage-in/garbage-out), but it **cannot** fabricate new facts (like Monty Python trivia) that aren't in the database.
  - **Graph Completion**: When the retrieval phase returns empty or irrelevant context, the internal LLM falls back to its training data to answer the query, resulting in "fabrication".
- **Secondary Finding**: The result from `GRAPH_COMPLETION` typically lacks a similarity score (because it's a generation, not a retrieval). `retrieve.py` defaults this missing score to `0.7`.
  ```python
  score = getattr(result, 'score', None)
  if score is None:
      score = getattr(result, 'semantic_score', 0.7) # Default to 0.7 if missing
  ```
- **Impact**: The system takes an LLM generation (potentially a hallucination), assigns it a high confidence score (0.7), and presents it to the user/Copilot as a "Retrieved Memory". This confirms the user's suspicion that the result is fabricated, but identifies the source as **Cognee's internal LLM**, not the Copilot Chat LLM.

### 2. Silent Storage Failure
**Symptom**: Users store a memory, get a "staged" success message, but the memory never appears, and no error notification is shown.
**Investigation**:
- Reviewed `extension/src/background/BackgroundOperationManager.ts`.
- The manager spawns the background process and listens for exit.
- On exit, it calls `handleProcessExit`, which calls `processStatusStub`.
- `processStatusStub` attempts to read `.cognee/background_ops/<op_id>.json`.
- If the stub is found:
  - If `success: true`, it completes the operation (success notification).
  - If `success: false`, it fails the operation (failure notification).
- **Critical Finding**: If the stub is **not found** (e.g., process crashed, was killed, or failed to write stub due to error), `processStatusStub` returns `false`.
  ```typescript
  if (!processed) {
      entry.status = 'unknown';
      entry.lastUpdate = new Date().toISOString();
      await this.saveLedger();
  }
  ```
- **Impact**: When `processed` is false, the status is set to `unknown`, and the ledger is saved. **No notification is triggered.** The user is left thinking the operation is still running or finished successfully (since they saw the "staged" message), but it actually failed silently.
// ...existing code...
- **Secondary Finding**: `ingest.py` attempts to write a failure stub in `except` blocks, but if the script crashes (segfault, OOM) or is killed by the OS, no stub is written.

### 3. Observability Gap (The "Black Box")
**Symptom**: When the background process crashes, there are no logs explaining why.
**Investigation**:
- Reviewed `spawnCognifyProcess` in `BackgroundOperationManager.ts`.
- **Critical Finding**: The background process is spawned with `stdio: 'ignore'`.
  ```typescript
  const child = spawn(pythonExecutable, args, {
      detached: true,
      stdio: 'ignore', // <--- CRITICAL: Discards all stdout/stderr
      cwd: path.dirname(bridgeScriptPath)
  });
  ```
- **Impact**: If the Python process prints a stack trace, an import error, or a segmentation fault message to `stderr` before dying, **it is discarded**. The extension has no way to know *why* the process failed, only that it exited. This makes troubleshooting "silent failures" nearly impossible without manual reproduction.

## Methodology
// ...existing code...
// ...existing code...
2. **Silent Storage Failure**: Caused by `BackgroundOperationManager` failing to notify the user when a background operation finishes without a status stub (marking it as `unknown` instead of `failed`).
3. **Observability Gap**: The extension explicitly discards `stdout` and `stderr` from the background process, blinding developers to the root cause of crashes.

## Strategic Considerations
// ...existing code...
// ...existing code...
  - **Global Exception Handling**: Wrap the entire execution in a `try...finally` block to guarantee a status stub is written even if the script crashes unexpectedly.

### 3. Observability Strategy (Logging)
- **Capture Stdio**: Modify `BackgroundOperationManager.ts` to redirect `stdout` and `stderr` of the background process to a persistent log file (e.g., `.cognee/logs/ingest.log`) instead of ignoring them.
- **Log Rotation**: Implement simple log rotation (append-only, clear on startup, or max size) to prevent the log file from growing indefinitely.
- **Error Correlation**: When a process fails, include the last few lines of this log file in the error details or provide a "View Logs" button that opens this specific file.

### 4. Prevention Strategy (Proactive)
- **Payload Validation**: Enforce character limits in TypeScript (e.g., max 100k chars) before accepting an ingestion request to prevent Out-Of-Memory (OOM) crashes in the Python bridge.
// ...existing code...

## Methodology
- **Code Review**: Analyzed `extension/bridge/retrieve.py`, `extension/bridge/ingest.py`, and `extension/src/background/BackgroundOperationManager.ts`.
- **Trace Analysis**: Traced the execution flow for retrieval and async ingestion.
- **Logic Verification**: Verified the default scoring logic and the missing stub handling logic.

## Findings
1. **Retrieval Fabrication**: Caused by `retrieve.py` using `SearchType.GRAPH_COMPLETION`, which generates text via an LLM. `retrieve.py` then assigns a default score of `0.7` to this unscored generation, presenting hallucinations or meta-commentary as high-confidence memories.
2. **Silent Storage Failure**: Caused by `BackgroundOperationManager` failing to notify the user when a background operation finishes without a status stub (marking it as `unknown` instead of `failed`).

## Strategic Considerations
- **Trust**: Both issues severely damage user trust. Fabrication makes the tool unreliable, and silent failure makes it unpredictable.
- **Alignment**: Fixing these aligns with the "Zero Cognitive Overhead" principle (users shouldn't have to guess if it worked) and "Natural Language Retrieval" (retrieval should be accurate).

## Recommendations

### 1. Fix Retrieval Scoring
- **Immediate Fix**: Change the default score in `retrieve.py` from `0.7` to `0.0`. This ensures that unscored LLM generations (from `GRAPH_COMPLETION`) are treated as low-relevance and likely filtered out.
- **Strategic Fix**: Evaluate switching `retrieve.py` to use `SearchType.VECTOR` or `SearchType.GRAPH` (chunks) instead of `GRAPH_COMPLETION` (generative) to ensure results are actual retrieved memories, not LLM hallucinations.
- **Action**: Modify `extension/bridge/retrieve.py` to default `semantic_score` to `0.0`.

### 2. Fix Silent Storage Failure (Visibility)
- **Immediate Fix**: Update `BackgroundOperationManager.ts` to treat missing stubs as failures. If the process exits and no stub is found, call `failOperation` with a generic "Process crashed or was killed" error. This ensures the user receives the **same failure toast notification** as other errors.
- **Robustness Fix**: Update `ingest.py` to include:
  - **Signal Handlers**: Catch `SIGTERM` and `SIGINT` to write a "Process Terminated" status stub before exiting.
  - **Global Exception Handling**: Wrap the entire execution in a `try...finally` block to guarantee a status stub is written even if the script crashes unexpectedly.

### 3. Prevention Strategy (Proactive)
- **Payload Validation**: Enforce character limits in TypeScript (e.g., max 100k chars) before accepting an ingestion request to prevent Out-Of-Memory (OOM) crashes in the Python bridge.
- **Zombie Cleanup**: Ensure `BackgroundOperationManager` aggressively cleans up stale lock files or zombie processes on startup to prevent database locking conflicts.
// ...existing code...
- **Concurrency Enforcement**: Strictly enforce the 2-process limit in `BackgroundOperationManager` to prevent resource exhaustion on the user's machine.

### 4. UX Enhancements & Rebranding
**Requirement 1: Ingestion Timestamp**
- **User Story**: As a user, I want to see exactly when an ingestion operation started so I can distinguish between multiple similar operations.
- **Implementation**: Update the `cognee.backgroundStatus` command (which is triggered by the "View Status" button on the success toast) to include the `startTime` in the QuickPick item description.
  - *Current*: `${elapsed} - ${digest}`
  - *New*: `${startTime} - ${elapsed} - ${digest}`

**Requirement 2: Rebranding to "RecallFlow"**
- **User Story**: As a product owner, I want all user-facing text to use the brand "RecallFlow" instead of "Cognee" to avoid trademark issues, while keeping the underlying codebase unchanged.
- **Scope**:
  - **Manifest (`package.json`)**:
    - Extension Display Name: "RecallFlow Chat Memory"
    - Description: "...using RecallFlow knowledge graphs"
    - Command Titles: "Capture to RecallFlow Memory", etc.
    - Command Categories: "RecallFlow"
    - Tool Display Names: "Store Memory in RecallFlow", "Retrieve RecallFlow Memory"
    - Tool Descriptions: Replace "Cognee" with "RecallFlow"
    - Chat Participant: Rename `@cognee-memory` to `@recallflow-memory` (requires changing `id` and `name` in `package.json` and `extension.ts`).
  - **Runtime Strings (`src/**/*.ts`)**:
    - Output Channel Names: "RecallFlow Memory", "RecallFlow Agent Activity"
    - Toast Messages: "RecallFlow initialization failed", etc.
    - Help Text: "RecallFlow Memory Help", etc.
  - **Constraints**:
    - Keep internal configuration keys (`cogneeMemory.*`) unchanged.
    - Keep internal class names (`CogneeClient`, `CogneeContextProvider`) unchanged.
    - Keep internal command IDs (`cognee.captureMessage`) unchanged (except chat participant ID which is user-facing).

## Scope Considerations
- These fixes are targeted bug fixes for v0.3.5/v0.3.6.
// ...existing code...
- They do not require architectural changes, just logic corrections.

## References
- `extension/bridge/retrieve.py`
- `extension/src/background/BackgroundOperationManager.ts`
